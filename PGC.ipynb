{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\"   # raw string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo o corpus e armazenando o conteúdo completo em *content* e as linhas em *paragraphs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras: 83919\n"
     ]
    }
   ],
   "source": [
    "fileName = \"corpus-textos-DC.txt\"\n",
    "\n",
    "document = open(fileName,'r', encoding='utf-8')\n",
    "content  = document.read()\n",
    "\n",
    "document = open(fileName,'r', encoding='utf-8')\n",
    "paragraphs = document.readlines()\n",
    "\n",
    "words = re.findall(regex, content)\n",
    "\n",
    "print (f\"Quantidade de palavras: {len(words)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo parágrafos em branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in paragraphs:\n",
    "    if paragraph == \"\\n\":\n",
    "        paragraphs.remove(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de parágrafos: 1682\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quantidade de parágrafos: {len(paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade e frequência de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 12425\n"
     ]
    }
   ],
   "source": [
    "frequencies = dict([])\n",
    "for w in words:\n",
    "    w = w.lower()\n",
    "    if w not in frequencies:\n",
    "        frequencies[w] = 0\n",
    "    frequencies[w] += 1\n",
    "print (f\"Tamanho do vocabulário: {len(frequencies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4091 - de\n",
      "2570 - a\n",
      "2554 - e\n",
      "2179 - que\n",
      "2140 - o\n",
      "1274 - em\n",
      "1194 - da\n",
      "1167 - do\n",
      "1070 - é\n",
      "1013 - um\n",
      "916 - para\n",
      "806 - com\n",
      "799 - uma\n",
      "681 - os\n",
      "660 - por\n",
      "644 - como\n",
      "622 - no\n",
      "615 - na\n",
      "586 - não\n",
      "512 - se\n"
     ]
    }
   ],
   "source": [
    "fs = sorted(frequencies, key=frequencies.get, reverse=True)\n",
    "for i in range(0,20):\n",
    "    print (f\"{frequencies[fs[i]]} - {fs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade e frequência de palavras após a remoção de stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário (sem stopwords): 12106\n"
     ]
    }
   ],
   "source": [
    "stopwordsPTfile = open(\"stopwords-pt.txt\",'r', encoding='utf-8')\n",
    "stopwords       = set([]) \n",
    "for s in stopwordsPTfile.readlines():\n",
    "    stopwords.add(s.strip().lower())\n",
    "    \n",
    "words       = re.findall(regex, content)\n",
    "frequencies = dict([])\n",
    "\n",
    "# quantidade de vezes no documento\n",
    "for w in words:\n",
    "    w = w.lower()\n",
    "    if w not in stopwords:\n",
    "        if w not in frequencies:\n",
    "            frequencies[w] = 0\n",
    "        frequencies[w] += 1\n",
    "        \n",
    "print (f\"Tamanho do vocabulário (sem stopwords): {len(frequencies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 - ciência\n",
      "188 - água\n",
      "99 - exemplo\n",
      "97 - vida\n",
      "96 - luz\n",
      "92 - história\n",
      "91 - química\n",
      "90 - tempo\n",
      "83 - mundo\n",
      "73 - moléculas\n",
      "73 - terra\n",
      "72 - física\n",
      "72 - cientistas\n",
      "69 - pesquisa\n",
      "66 - científica\n",
      "65 - brasil\n",
      "59 - carbono\n",
      "57 - universidade\n",
      "55 - corpo\n",
      "55 - estudos\n"
     ]
    }
   ],
   "source": [
    "fs = sorted(frequencies, key=frequencies.get, reverse=True)\n",
    "for i in range(0,20):\n",
    "    print (f\"{frequencies[fs[i]]} - {fs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = []\n",
    "palavras = []\n",
    "\n",
    "for word in words:\n",
    "    if(word != \"----------------------------------------------------------------------------------\"):\n",
    "        palavras.append(word)\n",
    "    else:\n",
    "        textos.append(palavras)\n",
    "        palavras = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'que', 'é', 'um', 'podcast', 'É', 'tipo', 'rádio', 'Como', 'faço', 'para', 'começar', 'a', 'ouvir', 'acessibilidade', 'cachorro', 'da', 'raça', 'Golden', 'Retriever', 'em', 'um', 'parque', 'com', 'a', 'língua', 'para', 'fora', 'e', 'usando', 'um', 'headphone', 'Certamente', 'ouvindo', 'o', 'Laços', 'podcast', 'O', 'termo', 'podcast', 'vem', 'da', 'junção', 'de', 'pod', 'personal', 'on', 'demand', 'e', 'cast', 'de', 'broadcast', 'sendo', 'portanto', 'uma', 'transmissão', 'pessoal', 'sob', 'demanda', 'É', 'como', 'um', 'programa', 'de', 'rádio', 'mas', 'você', 'pode', 'ouvir', 'pela', 'internet', 'ou', 'baixar', 'o', 'programa', 'quando', 'quiser', 'não', 'precisa', 'sintonizar', 'uma', 'frequência', 'de', 'rádio', 'em', 'um', 'horário', 'específico', 'para', 'ouvir', 'Podcasts', 'são', 'uma', 'ótima', 'forma', 'de', 'se', 'manter', 'atualizado', 'sobre', 'diversos', 'assuntos', 'de', 'seu', 'interesse', 'enquanto', 'realiza', 'outras', 'tarefas', 'como', 'limpar', 'a', 'casa', 'comer', 'caminhar', 'ou', 'pilotar', 'máquinas', 'agrícolas', 'Por', 'ser', 'apenas', 'áudio', 'não', 'demanda', 'a', 'mesma', 'atenção', 'necessária', 'para', 'se', 'assistir', 'a', 'um', 'vídeo', 'por', 'exemplo', 'No', 'transporte', 'público', 'enquanto', 'dirige', 'enquanto', 'espera', 'por', 'um', 'compromisso', 'qualquer', 'hora', 'é', 'hora', 'Não', 'há', 'uma', 'ordem', 'certa', 'para', 'começar', 'a', 'ouvir', 'nem', 'há', 'a', 'necessidade', 'de', 'ouvir', 'o', 'anterior', 'para', 'se', 'ouvir', 'o', 'próximo', 'basta', 'escolher', 'um', 'episódio', 'e', 'começar', 'Podcasts', 'geralmente', 'tratam', 'de', 'um', 'tema', 'central', 'com', 'cada', 'episódio', 'falando', 'de', 'um', 'assunto', 'específico', 'relacionado', 'a', 'esse', 'tema', 'Conteúdo', 'nerd', 'Nerdcast', 'política', 'internacional', 'Xadrez', 'Verbal', 'cinema', 'RapaduraCast', 'games', 'Jogabilidade', 'direito', 'Salvo', 'Melhor', 'Juízo', 'design', 'Visual', 'Mente', 'mulheres', 'que', 'marcaram', 'a', 'história', 'Ponto', 'G', 'e', 'é', 'claro', 'ciência', 'Falaremos', 'mais', 'sobre', 'podcasts', 'de', 'ciência', 'ao', 'longo', 'do', 'texto', 'Gostou', 'e', 'quer', 'começar', 'a', 'ouvir', 'mas', 'ainda', 'não', 'sabe', 'como', 'Siga', 'os', 'passos', '1', 'Baixe', 'e', 'instale', 'um', 'agregador', 'de', 'podcasts', 'no', 'seu', 'celular', 'como', 'o', 'iTunes', 'WeCast', 'Google', 'Podcasts', 'ou', 'o', 'Podcast', 'Addict', 'Usaremos', 'o', 'Podcast', 'Addict', 'a', 'partir', 'de', 'agora', '2', 'Abra', 'o', 'aplicativo', 'e', 'clique', 'no', 'sinal', 'de', 'no', 'canto', 'superior', 'direito', 'Nesta', 'tela', 'é', 'possível', 'ver', 'as', 'tendências', 'novidades', 'mais', 'baixados', 'em', 'cada', 'categoria', 'etc', 'Na', 'barra', 'superior', 'é', 'possível', 'ver', 'o', 'ícone', 'da', 'lupa', 'para', 'pesquisar', 'e', 'o', 'ícone', 'do', 'feed', 'RSS', 'para', 'assinar', 'um', 'podcast', 'pelo', 'link', 'do', 'feed', 'Vamos', 'abrir', 'a', 'lupa', 'e', 'pesquisar', 'um', 'podcast', '3', 'Pesquise', 'pelo', 'Naruhodo', 'podcast', 'comandado', 'por', 'Altay', 'de', 'Souza', 'e', 'Ken', 'Fujioka', 'que', 'se', 'propõe', 'a', 'responder', 'perguntas', 'como', 'Estralar', 'os', 'dedos', 'faz', 'mal', 'Porque', 'algumas', 'pessoas', 'passam', 'mal', 'ao', 'ver', 'sangue', 'e', 'Por', 'que', 'temos', 'pintas', 'em', 'nosso', 'corpo', 'sempre', 'com', 'embasamento', 'científico', 'em', 'episódios', 'com', 'aproximadamente', '30', 'minutos', '4', 'Nos', 'resultados', 'da', 'pesquisa', 'você', 'pode', 'ver', 'que', 'o', 'Naruhodo', 'tem', 'mais', 'de', '130', 'episódios', 'e', 'mais', 'de', 'vinte', 'mil', 'assinantes', 'Assine', 'o', 'podcast', 'se', 'quiser', 'ver', 'atualizações', 'e', 'então', 'abra', 'a', 'lista', 'de', 'episódios', '5', 'Selecione', 'algum', 'episódio', 'que', 'seja', 'do', 'seu', 'interesse', 'É', 'possível', 'ouvir', 'por', 'streaming', 'sem', 'a', 'necessidade', 'de', 'baixar', 'mas', 'para', 'isso', 'conexão', 'com', 'a', 'internet', 'é', 'necessária', 'enquanto', 'estiver', 'ouvindo', 'A', 'outra', 'opção', 'é', 'baixar', 'o', 'episódio', '6', 'Abra', 'as', 'opções', 'no', 'canto', 'superior', 'esquerdo', 'Em', 'Últimos', 'episódios', 'você', 'pode', 'ver', 'os', 'episódios', 'dos', 'últimos', 'sete', 'dias', 'de', 'todos', 'os', 'podcasts', 'em', 'que', 'estiver', 'inscrito', 'Em', 'Episódios', 'baixados', 'você', 'pode', 'ver', 'todos', 'os', 'episódios', 'que', 'foram', 'baixados', 'no', 'celular', 'Selecione', 'esta', 'opção', 'e', 'escolha', 'um', 'para', 'ouvir', '7', 'O', 'player', 'do', 'aplicativo', 'é', 'bem', 'simples', 'você', 'pode', 'pausar', 'continuar', 'adiantar', 'voltar', 'ir', 'para', 'o', 'próximo', 'ou', 'ao', 'anterior', 'caso', 'tenha', 'feito', 'uma', 'playlist', 'ligar', 'um', 'timer', 'e', 'alterar', 'a', 'velocidade', 'de', 'reprodução', 'ideal', 'para', 'quando', 'você', 'estiver', 'com', 'pouco', 'tempo', 'Nas', 'configurações', 'você', 'ainda', 'pode', 'ligar', 'desligar', 'a', 'atualização', 'automática', 'o', 'download', 'automático', 'remoção', 'automática', 'de', 'episódios', 'vistos', 'etc', 'Outras', 'formas', 'de', 'ouvir', 'A', 'extensão', 'do', 'Google', 'Chrome', 'PodStation', 'permite', 'buscar', 'podcasts', 'pelo', 'nome', 'procurar', 'pelo', 'feed', 'assinar', 'ver', 'os', 'últimos', 'episódios', 'dos', 'podcasts', 'que', 'tiver', 'assinado', 'executar', 'sem', 'baixar', 'ou', 'baixar', 'e', 'executar', 'pausar', 'alterar', 'a', 'velocidade', 'de', 'reprodução', 'etc', 'acessibilidade', 'Print', 'Screen', 'da', 'extensão', 'PodStation', 'visualizando', 'todos', 'os', 'episódios', 'do', 'SciCast', 'Ideal', 'para', 'ouvir', 'os', 'dois', 'maiores', 'podcasts', 'de', 'ciência', 'do', 'Brasil', 'Scicast', 'criado', 'pelo', 'falecido', 'Silmar', 'Geremia', 'hoje', 'conta', 'com', 'Tarik', 'Fernandes', 'Fernando', 'Malta', 'Marcelo', 'Guaxinim', 'dentre', 'outros', 'membros', 'e', 'convidados', 'Provavelmente', 'o', 'maior', 'podcast', 'de', 'ciência', 'do', 'Brasil', 'aborda', 'diversos', 'temas', 'de', 'forma', 'sempre', 'bem', 'fundamentada', 'e', 'bem-humorada', 'porque', 'a', 'ciência', 'tem', 'que', 'ser', 'divertida', 'Dragões', 'de', 'Garagem', 'criado', 'por', 'Luciano', 'Queiroz', 'é', 'um', 'dos', 'maiores', 'podcasts', 'de', 'ciência', 'do', 'Brasil', 'Além', 'do', 'podcast', 'o', 'Dragões', 'publica', 'uma', 'vez', 'por', 'semana', 'as', 'Cientirinhas', 'tirinhas', 'com', 'temática', 'científica', 'e', 'tem', 'um', 'canal', 'no', 'YouTube', 'onde', 'vídeos', 'sobre', 'notícias', 'são', 'postados', 'toda', 'sexta-feira', 'Ainda', 'é', 'possível', 'ouvir', 'pelo', 'Deezer', 'ou', 'pelo', 'Spotify', 'pesquisando', 'pelo', 'gênero', 'podcasts', 'acessibilidade', 'Print', 'Screen', 'do', 'Spotify', 'mostrando', 'o', 'resultado', 'da', 'busca', 'pelo', 'termo', 'podcast', 'Baixar', 'o', 'arquivo', 'mp3', 'diretamente', 'pelo', 'site', 'acessibilidade', 'Print', 'Screen', 'do', 'site', 'do', 'NeuroCast', 'podcast', 'sobre', 'neurociência', 'da', 'UFABC', 'Ouvir', 'pelo', 'Soundcloud', 'acessibilidade', 'Print', 'Screen', 'do', 'SoundCloud', 'do', 'podcast', 'Bug', 'Bites', 'sobre', 'entomologia', 'Ou', 'até', 'mesmo', 'pelo', 'Youtube', 'acessibilidade', 'Print', 'Screen', 'da', 'playlist', 'Xadrez', 'Verbal', 'Podcast', 'no', 'canal', 'do', 'Xadrez', 'Verbal', 'no', 'YouTube', 'Ainda', 'falando', 'sobre', 'podcasts', 'de', 'ciência', 'importante', 'citar', 'os', 'excelentes', 'PodEntender', 'Alô', 'Ciência', 'e', 'os', 'podcast', 'feitos', 'em', 'Universidades', 'como', 'o', 'Paideia', 'da', 'UFSCAR', 'o', 'Front', 'da', 'Ciência', 'da', 'UFRGS', 'o', 'Oxigênio', 'da', 'Unicamp', 'e', 'o', 'NeuroCast', 'da', 'UFABC', 'Podcasts', 'também', 'podem', 'ser', 'usados', 'na', 'educação', 'professores', 'disponibilizando', 'suas', 'aulas', 'em', 'áudio', 'para', 'que', 'os', 'alunos', 'revisem', 'a', 'matéria', 'em', 'qualquer', 'lugar', 'Pensando', 'em', 'criar', 'seu', 'próprio', 'podcast', 'Não', 'deixe', 'de', 'ver', 'os', 'tutoriais', 'do', 'Mundo', 'Podcast', 'aproveite', 'e', 'ouça', 'o', 'excelente', 'PodProgramar', 'Este', 'trecho', 'foi', 'apenas', 'uma', 'referência', 'ao', 'programa', 'Choque', 'de', 'cultura', 'Evite', 'distrações', 'ao', 'dirigir', 'Marcelo', 'Pena']\n"
     ]
    }
   ],
   "source": [
    "print(textos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos2 = []\n",
    "paragrafos = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    if(paragraph != \"----------------------------------------------------------------------------------\\n\"):\n",
    "        paragrafos.append(paragraph)\n",
    "    else:\n",
    "        textos2.append(paragrafos)\n",
    "        paragrafos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O que é um podcast? É tipo rádio? Como faço para começar a ouvir?\\n', '#acessibilidade cachorro da raça Golden Retriever em um parque com a língua para fora e usando um headphone. Certamente ouvindo o Laços podcast.\\n', 'O termo podcast vem da junção de pod (personal on demand) e cast (de broadcast), sendo portanto uma transmissão pessoal sob demanda. É como um programa de rádio, mas você pode ouvir pela internet ou baixar o programa quando quiser, não precisa sintonizar uma frequência de rádio em um horário específico para ouvir.\\n', 'Podcasts são uma ótima forma de se manter atualizado sobre diversos assuntos de seu interesse enquanto realiza outras tarefas como limpar a casa, comer, caminhar ou pilotar máquinas agrícolas. Por ser apenas áudio, não demanda a mesma atenção necessária para se assistir a um vídeo, por exemplo. No transporte público, enquanto dirige*, enquanto espera por um compromisso, qualquer hora é hora. Não há uma ordem certa para começar a ouvir, nem há a necessidade de ouvir o anterior para se ouvir o próximo, basta escolher um episódio e começar.\\n', 'Podcasts geralmente tratam de um tema central, com cada episódio falando de um assunto específico relacionado a esse tema. Conteúdo nerd (Nerdcast), política internacional (Xadrez Verbal), cinema (RapaduraCast), games (Jogabilidade), direito (Salvo Melhor Juízo), design (Visual+Mente), mulheres que marcaram a história (Ponto G) e, é claro, ciência! Falaremos mais sobre podcasts de ciência ao longo do texto.\\n', 'Gostou e quer começar a ouvir, mas ainda não sabe como? Siga os passos:\\n', '1. Baixe e instale um agregador de podcasts no seu celular, como o iTunes, WeCast, Google Podcasts ou o Podcast Addict. Usaremos o Podcast Addict a partir de agora.\\n', '2. Abra o aplicativo e clique no sinal de + no canto superior direito. Nesta tela é possível ver as tendências, novidades, mais baixados em cada categoria, etc. Na barra superior é possível ver o ícone da lupa para pesquisar e o ícone do feed RSS para assinar um podcast pelo link do feed. Vamos abrir a lupa e pesquisar um podcast.\\n', '3. Pesquise pelo Naruhodo, podcast comandado por Altay de Souza e Ken Fujioka, que se propõe a responder perguntas como “Estralar os dedos faz mal?”, “Porque algumas pessoas passam mal ao ver sangue?” e “Por que temos pintas em nosso corpo?”, sempre com embasamento científico em episódios com aproximadamente 30 minutos.\\n', '4. Nos resultados da pesquisa você pode ver que o Naruhodo tem mais de 130 episódios e mais de vinte mil assinantes. Assine o podcast se quiser ver atualizações e então abra a lista de episódios.\\n', '5. Selecione algum episódio que seja do seu interesse. É possível ouvir por streaming, sem a necessidade de baixar, mas para isso conexão com a internet é necessária enquanto estiver ouvindo. A outra opção é baixar o episódio.\\n', '6. Abra as opções no canto superior esquerdo. Em “Últimos episódios” você pode ver os episódios dos últimos sete dias de todos os podcasts em que estiver inscrito. Em “Episódios baixados” você pode ver todos os episódios que foram baixados no celular. Selecione esta opção e escolha um para ouvir.\\n', '7. O player do aplicativo é bem simples: você pode pausar/continuar, adiantar/voltar, ir para o próximo ou ao anterior caso tenha feito uma playlist, ligar um timer e alterar a velocidade de reprodução (ideal para quando você estiver com pouco tempo).\\n', 'Nas configurações você ainda pode ligar/desligar a atualização automática, o download automático, remoção automática de episódios vistos, etc.\\n', 'Outras formas de ouvir\\n', 'A extensão do Google Chrome PodStation permite buscar podcasts pelo nome, procurar pelo feed, assinar, ver os últimos episódios dos podcasts que tiver assinado, executar sem baixar ou baixar e executar, pausar, alterar a velocidade de reprodução, etc.\\n', '#acessibilidade Print Screen da extensão PodStation visualizando todos os episódios do SciCast\\n', 'Ideal para ouvir os dois maiores podcasts de ciência do Brasil:\\n', 'Scicast: criado pelo falecido Silmar Geremia, hoje conta com Tarik Fernandes, Fernando Malta, Marcelo Guaxinim, dentre outros membros e convidados. Provavelmente o maior podcast de ciência do Brasil, aborda diversos temas, de forma sempre bem fundamentada e bem-humorada, porque a ciência tem que ser divertida.\\n', 'Dragões de Garagem: criado por Luciano Queiroz, é um dos maiores podcasts de ciência do Brasil. Além do podcast, o Dragões publica uma vez por semana as Cientirinhas, tirinhas com temática científica, e tem um canal no YouTube onde vídeos sobre notícias são postados toda sexta-feira.\\n', 'Ainda é possível ouvir pelo Deezer ou pelo Spotify pesquisando pelo gênero podcasts.\\n', '#acessibilidade Print Screen do Spotify mostrando o resultado da busca pelo termo “podcast”\\n', 'Baixar o arquivo mp3 diretamente pelo site.\\n', '#acessibilidade Print Screen do site do NeuroCast, podcast sobre neurociência da UFABC\\n', 'Ouvir pelo Soundcloud.\\n', '#acessibilidade Print Screen do SoundCloud do podcast Bug Bites sobre entomologia\\n', 'Ou até mesmo pelo Youtube.\\n', '#acessibilidade Print Screen da playlist Xadrez Verbal Podcast no canal do Xadrez Verbal no YouTube\\n', 'Ainda falando sobre podcasts de ciência, importante citar os excelentes PodEntender, Alô, Ciência? e os podcast feitos em Universidades como o Paideia da UFSCAR, o Front da Ciência da UFRGS, o Oxigênio da Unicamp e o NeuroCast da UFABC.\\n', 'Podcasts também podem ser usados na educação: professores disponibilizando suas aulas em áudio para que os alunos revisem a matéria em qualquer lugar.\\n', 'Pensando em criar seu próprio podcast? Não deixe de ver os tutoriais do Mundo Podcast  (aproveite e ouça o excelente PodProgramar).\\n', '*Este trecho foi apenas uma referência ao programa “Choque de cultura”. Evite distrações ao dirigir.\\n', 'Marcelo Pena\\n']\n"
     ]
    }
   ],
   "source": [
    "print(textos2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 22, 65, 20, 56, 32, 36, 52, 31, 71, 46, 21, 37, 29, 37, 39, 54, 24, 14, 25, 24, 40, 23, 40, 70, 45, 32, 22, 36, 33, 25, 26, 52, 63, 36, 45, 51, 18, 34, 11, 74, 35, 20, 22, 15, 64, 23, 40, 37, 42, 52, 78, 48, 23, 71, 7, 28, 27, 44, 7, 27, 26, 29, 46, 57, 42, 53, 40, 29, 52, 45, 68, 45, 74, 54, 33, 36, 56, 45, 69, 25, 32, 27, 51, 36, 46, 42, 27, 66, 43, 42, 78, 60, 38, 22, 61, 38, 25, 91, 37, 52, 65, 49, 31, 68, 61, 37, 31, 55, 30, 34, 43, 21, 26, 37, 22, 51, 59]\n"
     ]
    }
   ],
   "source": [
    "tamanhoTitulo = []\n",
    "for i in range (len(textos2)):\n",
    "    tamanhoTitulo.append(len(textos2[i][0][:-1]))\n",
    "\n",
    "print(tamanhoTitulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maior parágrafo tem 2287 caracteres\n",
      "Texto: [ENTREVISTA] Água em Marte: os próximos passos para a pesquisa espacial \n",
      "Parágrafo:\n",
      "\t Eu fiz faculdade de Ciências Biológicas na Universidade Estadual de Londrina, Mestrado em Genética e Biologia Molecular lá também, na área de controle biológico de fungos controladores de pragas da agricultura. Para o meu doutorado queria algo relacionado à astrobiologia, pois sabia que isso iria definir minha carreira. Em 2006 teve o Primeiro Workshop de Astrobiologia do Brasil no Rio de Janeiro, onde conheci a Prof Claudia Lage, do Instituto de Biofísica Carlos Chagas Filho da Universidade Federal do Rio de Janeiro. Escrevemos um projeto e fui aprovado em segundo lugar no programa de doutorado lá. Minha tese foi sobre os limites de sobrevivência da bactéria Deinococcus Radiodurans em condições extraterrestres, verificando os efeitos da radiação cósmica nessa bactéria. Em 2009 tive a oportunidade de fazer um estágio sanduíche na Open University, Inglaterra, onde tive contato com vários pesquisadores de renome na Europa e fiz experimentos em Oxford, Irlanda do Norte, Dinamarca e Itália. Em 2010 o Instituto de Astronomia, Geofísica e Ciências Atmosféricas da Universidade de São Paulo promoveu um curso avançado de Astrofísica em São José dos Campos e convidou a pesquisadora da NASA, Lynn Rothschild. A data coincidia com a época da minha defesa de tese. Convidei ela para ser banca da minha tese e para minha surpresa ela aceitou! Defendi o doutorado e apresentei um projeto de pós-doutorado para fazer lá com ela. Consegui uma bolsa da CAPES e quando cheguei lá em 2011 consegui uma bolsa da NASA. Concluí o meu pós doutorado em 2015 e fui contratado como Microbiologista Sênior para trabalhar como Co-Investigador Principal em uma missão espacial e estou lá até hoje. Importante salientar que eu não sou pesquisador da NASA. Eu trabalho para um instituto de pesquisa que presta serviço para a NASA, chamado Blue Marble Space Institute of Science. Meu escritório e meu laboratório são dentro da NASA, mas eu sou cientista do BMSIS na NASA. Aqui no Brasil eu faço parte da equipe científica da Primeira Missão Lunar Brasileira, chamada Garatea-L, e colaboro também no projeto Garatea-ISS, que desde o ano passado tem permitido que alunos do ensino básico enviem experimentos para a Estação Espacial Internacional, ambos liderados pelo meu amigo engenheiro Lucas Fonseca.\n",
      "[308, 204, 180, 514, 340, 332, 472, 384, 478, 378, 265, 337, 440, 530, 342, 335, 464, 219, 518, 313, 563, 247, 301, 539, 584, 355, 451, 249, 506, 419, 387, 436, 212, 304, 612, 570, 482, 476, 562, 589, 294, 353, 316, 443, 571, 496, 555, 421, 474, 504, 184, 434, 240, 484, 358, 636, 290, 388, 240, 218, 242, 466, 476, 547, 406, 358, 599, 302, 545, 300, 540, 655, 608, 559, 567, 423, 472, 303, 391, 356, 532, 424, 398, 368, 672, 428, 425, 395, 432, 183, 645, 267, 460, 324, 309, 788, 602, 684, 294, 274, 430, 246, 460, 435, 685, 426, 460, 431, 321, 293, 342, 689, 408, 416, 171, 615, 460, 234]\n"
     ]
    }
   ],
   "source": [
    "mediaParagrafos = []\n",
    "tamanhoParagrafos = []\n",
    "aux = []\n",
    "maior = 0\n",
    "txtMaior = 0\n",
    "parMaior = 0\n",
    "\n",
    "for i in range (len(textos2)):\n",
    "    for j in range (1,len(textos2[i])-1):\n",
    "        aux.append(len(textos2[i][j][:-1]))\n",
    "        if len(textos2[i][j][:-1]) > maior:\n",
    "            maior = len(textos2[i][j][:-1])\n",
    "            txtMaior = i\n",
    "            parMaior = j\n",
    "    #print(tamanhoParagrafos)\n",
    "    #print(sum(tamanhoParagrafos))\n",
    "    #print(len(tamanhoParagrafos))\n",
    "    #print(sum(tamanhoParagrafos)/len(tamanhoParagrafos))\n",
    "    mediaParagrafos.append(round(sum(aux)/len(aux)))\n",
    "    tamanhoParagrafos.append(aux)\n",
    "    aux = []\n",
    "\n",
    "print(\"Maior parágrafo tem\",len(textos2[txtMaior][parMaior][:-1]),\n",
    "      \"caracteres\\nTexto:\",textos2[txtMaior][0][:-1],\n",
    "      \"\\nParágrafo:\\n\\t\",textos2[txtMaior][parMaior][:-1])\n",
    "\n",
    "#print(tamanhoParagrafos)\n",
    "print(mediaParagrafos)\n",
    "#print(textos2[115][5])\n",
    "#print(len(textos2[115][5][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "postagging = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = postagging(textos2[i][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Paradoxo de Simpson te mostra que nem tudo é o que parece\n"
     ]
    }
   ],
   "source": [
    "print(parsedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavra: O \n",
      "Lemma: O \n",
      "Postag: DET \n",
      "\n",
      "Palavra: Paradoxo \n",
      "Lemma: Paradoxo \n",
      "Postag: PROPN \n",
      "\n",
      "Palavra: de \n",
      "Lemma: de \n",
      "Postag: ADP \n",
      "\n",
      "Palavra: Simpson \n",
      "Lemma: Simpson \n",
      "Postag: PROPN \n",
      "\n",
      "Palavra: te \n",
      "Lemma: te \n",
      "Postag: PROPN \n",
      "\n",
      "Palavra: mostra \n",
      "Lemma: mostrar \n",
      "Postag: VERB \n",
      "\n",
      "Palavra: que \n",
      "Lemma: que \n",
      "Postag: SCONJ \n",
      "\n",
      "Palavra: nem \n",
      "Lemma: nem \n",
      "Postag: ADV \n",
      "\n",
      "Palavra: tudo \n",
      "Lemma: tudo \n",
      "Postag: PRON \n",
      "\n",
      "Palavra: é \n",
      "Lemma: ser \n",
      "Postag: VERB \n",
      "\n",
      "Palavra: o \n",
      "Lemma: o \n",
      "Postag: PRON \n",
      "\n",
      "Palavra: que \n",
      "Lemma: que \n",
      "Postag: PRON \n",
      "\n",
      "Palavra: parece \n",
      "Lemma: parecer \n",
      "Postag: VERB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j,word in enumerate(parsedData):\n",
    "    print(\"Palavra:\",word.text,\"\\nLemma:\",word.lemma_,\"\\nPostag:\",word.pos_,\"\\n\")#,word.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paradoxo LOC\n",
      "Simpson PER\n"
     ]
    }
   ],
   "source": [
    "for word in parsedData:\n",
    "    if word.ent_type_:\n",
    "        print(word.text, word.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.577 segundos\n"
     ]
    }
   ],
   "source": [
    "t=time.perf_counter()\n",
    "\n",
    "nNounsTotal = []\n",
    "nAdjTotal = []\n",
    "nVerbTotal = []\n",
    "nNesTotal = []\n",
    "nDetTotal = []\n",
    "nConjTotal = []\n",
    "nAdvTotal = []\n",
    "nAdpTotal = []\n",
    "nNumTotal = []\n",
    "#xTotal = []\n",
    "\n",
    "for k in range (len(textos)):\n",
    "    nNouns = 0\n",
    "    nAdj = 0\n",
    "    nVerb = 0\n",
    "    nNes = 0\n",
    "    nDet = 0\n",
    "    nConj = 0\n",
    "    nAdv = 0\n",
    "    nAdp = 0\n",
    "    nNum = 0\n",
    "    #x = 0\n",
    "    for l in range (len(textos2[k])):        \n",
    "        parsedData = postagging(textos2[k][l])\n",
    "        for j,palavra in enumerate(parsedData):\n",
    "            tag = palavra.pos_\n",
    "            if tag in [\"NOUN\",\"PROPN\"]:\n",
    "                nNouns += 1\n",
    "            elif tag in [\"ADJ\"]:\n",
    "                nAdj += 1\n",
    "            elif tag in [\"VERB\"]:\n",
    "                nVerb += 1\n",
    "            elif tag in [\"DET\"]:\n",
    "                nDet += 1\n",
    "            elif tag in [\"CONJ\",\"CCONJ\"]:\n",
    "                nConj += 1\n",
    "            elif tag in [\"ADV\"]:\n",
    "                nAdv += 1\n",
    "            elif tag in [\"NUM\"]:\n",
    "                nNum += 1\n",
    "            elif tag in [\"ADP\"]:\n",
    "                nAdp += 1\n",
    "            #elif tag in [\"X\"]: # fazer sem stopwords\n",
    "            #    x += 1\n",
    "                #print(palavra)\n",
    "            if palavra.ent_type_:\n",
    "                nNes += 1\n",
    "            #print(\"Palavra:\",palavra.text,\"\\nLemma:\",palavra.lemma_,\"\\nPostag:\",palavra.pos_,\"\\n\") #word.tag_)\n",
    "    nNounsTotal.append(nNouns)\n",
    "    nAdjTotal.append(nAdj)\n",
    "    nVerbTotal.append(nVerb)\n",
    "    nNesTotal.append(nNes)\n",
    "    nDetTotal.append(nDet)\n",
    "    nConjTotal.append(nConj)\n",
    "    nAdvTotal.append(nAdv)\n",
    "    nAdpTotal.append(nAdp)\n",
    "    nNumTotal.append(nNum)\n",
    "    #xTotal.append(x)\n",
    "    \n",
    "print(round(time.perf_counter()-t,3), \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substantivos: [137, 223, 322, 120, 227, 116, 142, 103, 185, 382, 140, 85, 103, 187, 100, 139, 102, 198, 219, 264, 224, 118, 84, 134, 251, 114, 141, 530, 102, 99, 103, 107, 73, 271, 182, 116, 169, 145, 158, 227, 248, 169, 94, 201, 370, 128, 323, 178, 144, 172, 358, 222, 127, 174, 116, 347, 284, 358, 170, 113, 122, 494, 293, 364, 229, 297, 110, 144, 230, 366, 263, 285, 222, 133, 234, 98, 120, 188, 326, 243, 189, 482, 477, 591, 331, 392, 416, 172, 329, 172, 431, 262, 425, 232, 225, 233, 210, 280, 205, 155, 320, 226, 255, 358, 230, 285, 150, 202, 173, 383, 107, 246, 285, 182, 187, 195, 182, 202]\n",
      "Adjetivos: [30, 37, 42, 20, 40, 25, 26, 14, 25, 70, 26, 22, 43, 26, 25, 24, 38, 49, 40, 38, 63, 35, 27, 38, 38, 22, 40, 104, 32, 26, 19, 33, 20, 63, 54, 38, 40, 36, 27, 61, 36, 36, 21, 57, 67, 26, 88, 53, 40, 34, 59, 61, 26, 57, 36, 62, 69, 67, 37, 28, 24, 116, 86, 66, 69, 61, 29, 34, 52, 67, 60, 66, 45, 31, 71, 19, 26, 44, 47, 44, 47, 77, 104, 71, 122, 78, 71, 39, 125, 32, 104, 33, 65, 46, 60, 65, 46, 85, 70, 34, 64, 65, 61, 108, 69, 71, 52, 45, 34, 85, 36, 87, 82, 67, 72, 61, 35, 46]\n",
      "Verbos: [41, 60, 152, 43, 55, 53, 56, 54, 86, 140, 60, 48, 31, 63, 50, 64, 40, 145, 75, 78, 68, 73, 32, 64, 105, 51, 42, 287, 48, 59, 35, 54, 24, 183, 79, 44, 45, 65, 47, 89, 64, 76, 38, 94, 124, 32, 133, 87, 81, 128, 128, 59, 41, 103, 37, 88, 105, 90, 58, 44, 64, 229, 189, 164, 96, 119, 65, 61, 103, 204, 98, 94, 146, 86, 82, 66, 74, 90, 126, 96, 78, 129, 198, 186, 205, 168, 172, 65, 158, 128, 153, 95, 181, 93, 113, 109, 76, 164, 112, 99, 168, 94, 101, 141, 106, 130, 76, 81, 76, 168, 80, 168, 142, 64, 123, 104, 88, 104]\n",
      "Entidades nomeadas: [47, 79, 109, 20, 86, 27, 21, 11, 13, 123, 46, 11, 6, 33, 16, 14, 11, 42, 86, 134, 39, 16, 13, 19, 92, 7, 34, 133, 7, 13, 20, 4, 11, 28, 26, 13, 42, 13, 36, 18, 101, 92, 18, 8, 72, 27, 34, 15, 40, 8, 110, 25, 27, 13, 26, 123, 17, 115, 57, 8, 19, 120, 30, 121, 26, 61, 9, 11, 48, 52, 66, 61, 16, 5, 19, 6, 3, 34, 85, 65, 21, 206, 100, 269, 56, 228, 146, 11, 30, 23, 92, 99, 77, 69, 46, 58, 53, 29, 35, 9, 8, 68, 105, 61, 29, 13, 24, 21, 14, 64, 10, 50, 32, 29, 14, 7, 36, 35]\n",
      "Determinantes: [39, 66, 118, 37, 69, 51, 51, 51, 93, 149, 68, 43, 39, 76, 45, 62, 42, 101, 74, 86, 71, 42, 35, 57, 114, 55, 52, 201, 37, 45, 38, 46, 25, 150, 89, 48, 62, 83, 75, 58, 73, 57, 37, 85, 129, 40, 147, 66, 78, 74, 137, 78, 51, 89, 45, 116, 87, 133, 74, 44, 46, 201, 175, 144, 110, 125, 45, 69, 101, 163, 110, 116, 104, 66, 87, 44, 51, 83, 124, 89, 60, 147, 175, 177, 158, 177, 176, 82, 170, 96, 177, 79, 164, 74, 101, 88, 83, 175, 91, 70, 145, 71, 78, 177, 108, 138, 62, 78, 88, 137, 53, 115, 145, 86, 102, 78, 98, 100]\n",
      "Conjunções: [11, 23, 29, 14, 18, 7, 15, 12, 15, 22, 13, 9, 12, 14, 17, 18, 12, 29, 23, 15, 18, 11, 4, 17, 24, 7, 7, 69, 8, 7, 14, 15, 9, 34, 18, 9, 14, 14, 16, 29, 17, 12, 9, 27, 20, 8, 45, 24, 12, 19, 23, 31, 13, 26, 11, 38, 15, 42, 18, 16, 14, 76, 49, 50, 21, 34, 20, 16, 19, 48, 29, 36, 36, 15, 23, 14, 24, 16, 27, 26, 23, 66, 57, 51, 37, 34, 59, 19, 56, 16, 24, 20, 38, 24, 25, 26, 17, 40, 34, 17, 39, 34, 19, 37, 30, 34, 25, 24, 9, 37, 20, 49, 45, 32, 26, 15, 19, 19]\n",
      "Advérbios: [15, 13, 53, 10, 20, 21, 15, 16, 35, 72, 26, 15, 12, 22, 22, 20, 18, 77, 39, 44, 33, 20, 6, 26, 52, 23, 10, 107, 13, 27, 18, 21, 14, 83, 38, 18, 11, 30, 18, 40, 17, 36, 7, 45, 52, 14, 54, 29, 27, 54, 57, 30, 17, 48, 22, 18, 26, 36, 34, 21, 34, 127, 63, 46, 44, 66, 26, 27, 43, 102, 49, 26, 77, 32, 50, 31, 32, 38, 81, 48, 29, 42, 102, 77, 102, 61, 79, 21, 71, 50, 81, 49, 61, 36, 60, 49, 27, 92, 49, 42, 70, 42, 46, 73, 50, 45, 39, 25, 39, 66, 36, 63, 47, 24, 52, 44, 36, 41]\n",
      "Adposições: [49, 84, 132, 58, 107, 58, 65, 56, 95, 184, 71, 44, 42, 90, 52, 67, 53, 86, 91, 118, 96, 44, 35, 73, 115, 69, 53, 269, 52, 42, 45, 56, 25, 144, 115, 58, 72, 81, 69, 132, 87, 82, 44, 103, 181, 69, 162, 99, 71, 91, 165, 111, 53, 99, 49, 136, 128, 151, 83, 42, 55, 266, 148, 177, 113, 176, 49, 63, 115, 203, 138, 148, 90, 59, 114, 46, 49, 86, 165, 110, 97, 218, 221, 207, 167, 195, 222, 95, 168, 71, 256, 104, 174, 112, 108, 101, 95, 163, 83, 61, 162, 101, 119, 191, 121, 136, 86, 106, 86, 184, 51, 131, 133, 69, 79, 93, 89, 100]\n",
      "Numerais: [4, 8, 16, 4, 14, 17, 0, 7, 0, 7, 2, 0, 9, 2, 1, 2, 5, 8, 9, 24, 7, 7, 1, 2, 7, 8, 7, 8, 1, 3, 4, 0, 1, 10, 7, 2, 8, 7, 0, 2, 6, 10, 3, 10, 41, 9, 7, 2, 7, 1, 33, 10, 5, 5, 2, 10, 5, 14, 0, 1, 0, 52, 2, 24, 11, 11, 12, 1, 8, 26, 6, 26, 9, 5, 6, 3, 1, 8, 30, 13, 1, 10, 37, 33, 9, 33, 29, 3, 2, 3, 31, 12, 15, 9, 10, 13, 6, 20, 13, 9, 11, 12, 12, 30, 2, 18, 7, 14, 10, 51, 1, 47, 12, 4, 57, 0, 13, 70]\n"
     ]
    }
   ],
   "source": [
    "print(\"Substantivos:\",nNounsTotal)\n",
    "print(\"Adjetivos:\",nAdjTotal)\n",
    "print(\"Verbos:\",nVerbTotal)\n",
    "print(\"Entidades nomeadas:\",nNesTotal)\n",
    "print(\"Determinantes:\",nDetTotal)\n",
    "print(\"Conjunções:\",nConjTotal)\n",
    "print(\"Advérbios:\",nAdvTotal)\n",
    "print(\"Adposições:\",nAdpTotal)\n",
    "print(\"Numerais:\",nNumTotal)\n",
    "#print(\"Desconhecidos:\",xTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPalavras = []\n",
    "nParagrafos = []\n",
    "\n",
    "for num in range (len(textos)):\n",
    "    nPalavras.append(len(textos[num]))\n",
    "    nParagrafos.append(len(textos2[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345, 532, 913, 322, 557, 400, 400, 345, 577, 1129, 439, 311, 300, 516, 345, 449, 341, 799, 609, 714, 612, 375, 236, 438, 766, 381, 371, 1757, 330, 339, 292, 355, 203, 1052, 619, 363, 435, 487, 426, 678, 584, 529, 271, 691, 1079, 335, 1044, 583, 511, 668, 1031, 631, 348, 678, 342, 855, 768, 913, 515, 327, 389, 1702, 1153, 1124, 758, 947, 392, 443, 706, 1324, 810, 851, 816, 472, 697, 367, 406, 613, 973, 737, 576, 1228, 1441, 1452, 1252, 1249, 1309, 533, 1171, 651, 1341, 731, 1200, 687, 782, 749, 580, 1152, 749, 552, 1083, 685, 756, 1236, 779, 934, 554, 606, 564, 1219, 437, 1011, 987, 563, 788, 652, 608, 759]\n",
      "[9, 18, 33, 6, 13, 9, 7, 7, 9, 20, 11, 7, 7, 8, 8, 10, 7, 23, 9, 16, 9, 11, 7, 7, 10, 8, 7, 46, 6, 7, 7, 7, 8, 23, 8, 6, 8, 8, 7, 10, 14, 11, 7, 11, 13, 6, 14, 11, 8, 10, 35, 11, 11, 11, 8, 11, 19, 16, 15, 11, 12, 24, 17, 15, 13, 18, 6, 11, 10, 28, 11, 10, 10, 7, 10, 7, 7, 14, 17, 15, 9, 20, 24, 25, 14, 20, 20, 10, 19, 22, 15, 18, 18, 15, 17, 8, 8, 12, 18, 14, 17, 19, 12, 19, 9, 15, 9, 11, 12, 27, 10, 11, 17, 11, 28, 9, 10, 21]\n"
     ]
    }
   ],
   "source": [
    "print(nPalavras)\n",
    "print(nParagrafos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = []\n",
    "for i in range (len(textos2)):\n",
    "    titulos.append(textos2[i][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = []\n",
    "\n",
    "for titulo in titulos:\n",
    "    if(titulo.find('?') != -1):\n",
    "        pergunta.append(1)\n",
    "    else:\n",
    "        pergunta.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livro - Professor, para que estudo isso?\n",
      "Coleção Contém Química\n",
      "O que é um podcast? É tipo rádio? Como faço para começar a ouvir?\n",
      "Nojo no mundo animal\n",
      "Prêmio Nobel 2017 – Microscopia Eletrônica com Criogenia\n",
      "Que seja eterno enquanto dure...\n",
      "O que dá cor aos fogos de artifício?\n",
      "Por que café descafeinado tem gosto e aroma de café?\n",
      "Arco-íris de sons? O que seria?\n",
      "[ENTREVISTA] Água em Marte: os próximos passos para a pesquisa espacial\n",
      "Lua de Sangue: entenda como funciona o Eclipse\n",
      "Por que o céu é azul?\n",
      "Estratégias de contracepção masculina\n",
      "Os alquimistas estão chegando\n",
      "E se acabássemos com o efeito estufa?\n",
      "A ciência que você vê, mas não percebe!\n",
      "Pílula anticoncepcional para o homem: é uma realidade?\n",
      "Se sentindo um impostor?\n",
      "O voo de Ícaro\n",
      "O Roubo da Medalha Fields\n",
      "Colesterol pode ser bom?\n",
      "Números imaginários… Mas o quê? Por quê?\n",
      "Viagra feminino existe?\n",
      "O CO2 é o grande vilão do efeito estufa?\n",
      "Crônica de uma tragédia anunciada: a morte assistida do Museu Nacional\n",
      "O que as vacas têm a ver com o efeito estufa?\n",
      "O sol faz bem para o seu coração\n",
      "Como ajudar a ciência?\n",
      "Pilhas de primeira e segunda geração\n",
      "A gente evolui, mas não progride!\n",
      "Todo remédio é uma droga?\n",
      "Posso beber água de chuva?\n",
      "Atenção colecionadores de conchas, últimas unidades!\n",
      "Preste atenção! Neurociência explica o que você viu mas não viu\n",
      "Resenha – O último teorema de Fermat\n",
      "Dopamina: a molécula da síndrome de Parkinson\n",
      "Prêmio Nobel em Medicina 2018 – Imunologia e Câncer\n",
      "Sábio era o Soneca\n",
      "Pesquisa, extensão e gerenciamento\n",
      "Microalgas?\n",
      "[Física e Química] Prêmio Nobel premia pesquisas com aplicações biológicas\n",
      "O Brasil nunca ganhou o Nobel, mas…\n",
      "O mistério da aurora\n",
      "O que é água alcalina?\n",
      "Quantos gramas?\n",
      "Sirius, a “estrela mais brilhante do céu noturno”, é inaugurado!\n",
      "O que (não) é quântica!\n",
      "Qual o papel do professor universitário?\n",
      "Natal, ano novo e o método científico\n",
      "Minha amiga samambaia! Tudo ouve, tudo vê!\n",
      "[RETROSPECTIVA] 10 fatos do mundo da ciência em 2018\n",
      "“Venho dos braços de Morfeu” – o que o ópio, a morfina e a heroína nos contam?\n",
      "Resenha – As dez maiores descobertas da medicina\n",
      "O POP não poupa ninguém\n",
      "Divulgação científica, jornalismo científico ou comunicação científica?\n",
      "ASTROEM\n",
      "Produtos de Reações Químicas\n",
      "Turma da Mônica e a ciência\n",
      "Resenha – O fim da eternidade – Isaac Asimov\n",
      "Lágrima\n",
      "Jogos deixam VOCÊ violento?\n",
      "Que delícia de mar, hein?!\n",
      "O que é um artigo científico?\n",
      "Uma breve história (da resistência) da ciência\n",
      "A posição do polo norte magnético da Terra foi redefinida\n",
      "Golden Show: Os museus do ouro na Colômbia\n",
      "Mudanças climáticas globais e a era dos walking deads\n",
      "Resenha – O menino que descobriu o vento\n",
      "A quantos graus ferve a água?\n",
      "Doação de Sangue: o que vem depois do fim da picada?\n",
      "Muito além de Mona Lisa, 500 anos de da Vinci\n",
      "Tempestade de 1 bilhão de volts é descoberta com telescópio de múons\n",
      "Maternidade na carreira acadêmica: depoimento\n",
      "Será que basta olhos para ver o arco-íris? Como os animais enxergam cores?\n",
      "“Tenho direito a quatro ligações!!!” – disse o Carbono\n",
      "A hora do sapo beber água, chega?\n",
      "O sapo não lava o pé, mas tem chulé?\n",
      "Aversão à perda e efeito dotação: uma pequena introdução\n",
      "1995: Stonewall – A luta pelo direito de amar\n",
      "Quando a ciência liberta: a pesquisa que separa preconceito de doença\n",
      "Microalgas para decoração\n",
      "A divulgação científica na UFABC\n",
      "Existe cura para o autismo?\n",
      "Se o homem foi à Lua em 1969, por que nunca voltou?\n",
      "Será que Einstein pode estar errado?\n",
      "2019 é o Ano Internacional da Tabela Periódica\n",
      "Museo de la Memoria y los Derechos Humanos\n",
      "Cores para além do colorido\n",
      "Investimentos públicos em ciência e tecnologia: alguns porquês sim\n",
      "“Mãe, porque a gente tem que tomar vacina?”\n",
      "Grafeno e o prêmio Nobel de Física de 2010\n",
      "Onde nenhum homem jamais esteve (ainda): Star Trek como precursor de invenções\n",
      "A importância da ciência básica e do investimento em ciência\n",
      "Ada Lovelace e os números de Bernoulli\n",
      "Quem foi Emmy Noether?\n",
      "Defensivos agrícolas ou agrotóxicos? Modernização ou vilania?\n",
      "Nobel de Medicina e Fisiologia de 2019\n",
      "Plástico: para sempre teu\n",
      "Além do POP, tem o HAP e o que essa sopa de letrinhas tem a ver com “o dia que virou noite”\n",
      "Por que as tatuagens são permanentes?\n",
      "Petróleo na praia: limpou tá limpo! Certo ou errado?\n",
      "Ostrava: cultura, história, ciência e tecnologia em uma só cidade\n",
      "O que falam sobre os jovens no Brasil não é sério\n",
      "Os Mitos e Mistérios de Saturno\n",
      "Por que usamos “cloro” (ou água sanitária) para limpar a nossa casa?\n",
      "O que acontece no seu corpo após tomar aquela cerveja gelada?\n",
      "Perigos de um cabelo liso e duradouro\n",
      "A química por trás da depressão\n",
      "Por que aquele saboroso cafezinho espanta o nosso sono?\n",
      "10 momentos da ciência em 2019\n",
      "O que são explicações exploráveis?\n",
      "A percepção dos brasileiros sobre a ciência\n",
      "A química dos sabores\n",
      "As especiarias e os aromas\n",
      "Existem infinitos maiores que outros?\n",
      "Seres Bioluminescentes\n",
      "O que tem a ver um tear com a era dos computadores?\n",
      "O Paradoxo de Simpson te mostra que nem tudo é o que parece\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(textos2)):\n",
    "    print(textos2[i][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 117 - O Paradoxo de Simpson te mostra que nem tudo é o que parece\n",
      "Autor: Marcelo Pena\n",
      "Número de palavras: 759\n",
      "Número de parágrafos: 21\n",
      "Número de substantivos: 202\n",
      "Número de adjetivos: 46\n",
      "Número de verbos: 104\n",
      "Número de Entidades Nomeadas: 35\n",
      "Número de Determinantes: 100\n",
      "Número de Conjunções: 19\n",
      "Número de Advérbios: 41\n",
      "Número de Adposições: 100\n",
      "Número de Numerais: 70\n",
      "Tamanho médio dos parágrafos: 234\n",
      "Número do título: 59\n",
      "É uma pergunta?: 0\n"
     ]
    }
   ],
   "source": [
    "i = 117\n",
    "print(f\"Texto {i} - {textos2[i][0][:-1]}\")\n",
    "print(f\"Autor: {textos2[i][-1][:-1]}\")\n",
    "print(f\"Número de palavras: {nPalavras[i]}\")\n",
    "print(f\"Número de parágrafos: {nParagrafos[i]}\") ####### Título e Autor contam como parágrafos\n",
    "print(f\"Número de substantivos: {nNounsTotal[i]}\")\n",
    "print(f\"Número de adjetivos: {nAdjTotal[i]}\")\n",
    "print(f\"Número de verbos: {nVerbTotal[i]}\")\n",
    "print(f\"Número de Entidades Nomeadas: {nNesTotal[i]}\")\n",
    "print(f\"Número de Determinantes:\",nDetTotal[i])\n",
    "print(f\"Número de Conjunções:\",nConjTotal[i])\n",
    "print(f\"Número de Advérbios:\",nAdvTotal[i])\n",
    "print(f\"Número de Adposições:\",nAdpTotal[i])\n",
    "print(f\"Número de Numerais:\",nNumTotal[i])\n",
    "print(f\"Tamanho médio dos parágrafos:\",mediaParagrafos[i])\n",
    "print(f\"Número do título:\",tamanhoTitulo[i])\n",
    "#print(f\"Número de Desconhecidos:\",xTotal[i])\n",
    "print(f\"É uma pergunta?: {pergunta[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes = ['numPal', 'numPar','numSub', 'numAdj', 'numVrb', 'numNEs','numDet',\n",
    "         'numConj','numAdv','numAdp','numNum','Pergunta','tamParagraf','tamTitulo']\n",
    "df = pd.DataFrame(list(zip(nPalavras, nParagrafos, nNounsTotal, nAdjTotal, nVerbTotal, nNesTotal,\n",
    "                           nDetTotal, nConjTotal, nAdvTotal, nAdpTotal, nNumTotal, \n",
    "                           pergunta, mediaParagrafos, tamanhoTitulo)),columns=nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     numPal  numPar  numSub  numAdj  numVrb  numNEs  numDet  numConj  numAdv  \\\n",
      "0       345       9     137      30      41      47      39       11      15   \n",
      "1       532      18     223      37      60      79      66       23      13   \n",
      "2       913      33     322      42     152     109     118       29      53   \n",
      "3       322       6     120      20      43      20      37       14      10   \n",
      "4       557      13     227      40      55      86      69       18      20   \n",
      "5       400       9     116      25      53      27      51        7      21   \n",
      "6       400       7     142      26      56      21      51       15      15   \n",
      "7       345       7     103      14      54      11      51       12      16   \n",
      "8       577       9     185      25      86      13      93       15      35   \n",
      "9      1129      20     382      70     140     123     149       22      72   \n",
      "10      439      11     140      26      60      46      68       13      26   \n",
      "11      311       7      85      22      48      11      43        9      15   \n",
      "12      300       7     103      43      31       6      39       12      12   \n",
      "13      516       8     187      26      63      33      76       14      22   \n",
      "14      345       8     100      25      50      16      45       17      22   \n",
      "15      449      10     139      24      64      14      62       18      20   \n",
      "16      341       7     102      38      40      11      42       12      18   \n",
      "17      799      23     198      49     145      42     101       29      77   \n",
      "18      609       9     219      40      75      86      74       23      39   \n",
      "19      714      16     264      38      78     134      86       15      44   \n",
      "20      612       9     224      63      68      39      71       18      33   \n",
      "21      375      11     118      35      73      16      42       11      20   \n",
      "22      236       7      84      27      32      13      35        4       6   \n",
      "23      438       7     134      38      64      19      57       17      26   \n",
      "24      766      10     251      38     105      92     114       24      52   \n",
      "25      381       8     114      22      51       7      55        7      23   \n",
      "26      371       7     141      40      42      34      52        7      10   \n",
      "27     1757      46     530     104     287     133     201       69     107   \n",
      "28      330       6     102      32      48       7      37        8      13   \n",
      "29      339       7      99      26      59      13      45        7      27   \n",
      "..      ...     ...     ...     ...     ...     ...     ...      ...     ...   \n",
      "88     1171      19     329     125     158      30     170       56      71   \n",
      "89      651      22     172      32     128      23      96       16      50   \n",
      "90     1341      15     431     104     153      92     177       24      81   \n",
      "91      731      18     262      33      95      99      79       20      49   \n",
      "92     1200      18     425      65     181      77     164       38      61   \n",
      "93      687      15     232      46      93      69      74       24      36   \n",
      "94      782      17     225      60     113      46     101       25      60   \n",
      "95      749       8     233      65     109      58      88       26      49   \n",
      "96      580       8     210      46      76      53      83       17      27   \n",
      "97     1152      12     280      85     164      29     175       40      92   \n",
      "98      749      18     205      70     112      35      91       34      49   \n",
      "99      552      14     155      34      99       9      70       17      42   \n",
      "100    1083      17     320      64     168       8     145       39      70   \n",
      "101     685      19     226      65      94      68      71       34      42   \n",
      "102     756      12     255      61     101     105      78       19      46   \n",
      "103    1236      19     358     108     141      61     177       37      73   \n",
      "104     779       9     230      69     106      29     108       30      50   \n",
      "105     934      15     285      71     130      13     138       34      45   \n",
      "106     554       9     150      52      76      24      62       25      39   \n",
      "107     606      11     202      45      81      21      78       24      25   \n",
      "108     564      12     173      34      76      14      88        9      39   \n",
      "109    1219      27     383      85     168      64     137       37      66   \n",
      "110     437      10     107      36      80      10      53       20      36   \n",
      "111    1011      11     246      87     168      50     115       49      63   \n",
      "112     987      17     285      82     142      32     145       45      47   \n",
      "113     563      11     182      67      64      29      86       32      24   \n",
      "114     788      28     187      72     123      14     102       26      52   \n",
      "115     652       9     195      61     104       7      78       15      44   \n",
      "116     608      10     182      35      88      36      98       19      36   \n",
      "117     759      21     202      46     104      35     100       19      41   \n",
      "\n",
      "     numAdp  numNum  Pergunta  tamParagraf  tamTitulo  \n",
      "0        49       4         1          308         40  \n",
      "1        84       8         0          204         22  \n",
      "2       132      16         1          180         65  \n",
      "3        58       4         0          514         20  \n",
      "4       107      14         0          340         56  \n",
      "5        58      17         0          332         32  \n",
      "6        65       0         1          472         36  \n",
      "7        56       7         1          384         52  \n",
      "8        95       0         1          478         31  \n",
      "9       184       7         0          378         71  \n",
      "10       71       2         0          265         46  \n",
      "11       44       0         1          337         21  \n",
      "12       42       9         0          440         37  \n",
      "13       90       2         0          530         29  \n",
      "14       52       1         1          342         37  \n",
      "15       67       2         0          335         39  \n",
      "16       53       5         1          464         54  \n",
      "17       86       8         1          219         24  \n",
      "18       91       9         0          518         14  \n",
      "19      118      24         0          313         25  \n",
      "20       96       7         1          563         24  \n",
      "21       44       7         1          247         40  \n",
      "22       35       1         1          301         23  \n",
      "23       73       2         1          539         40  \n",
      "24      115       7         0          584         70  \n",
      "25       69       8         1          355         45  \n",
      "26       53       7         0          451         32  \n",
      "27      269       8         1          249         22  \n",
      "28       52       1         0          506         36  \n",
      "29       42       3         0          419         33  \n",
      "..      ...     ...       ...          ...        ...  \n",
      "88      168       2         0          432         66  \n",
      "89       71       3         1          183         43  \n",
      "90      256      31         0          645         42  \n",
      "91      104      12         0          267         78  \n",
      "92      174      15         0          460         60  \n",
      "93      112       9         0          324         38  \n",
      "94      108      10         1          309         22  \n",
      "95      101      13         1          788         61  \n",
      "96       95       6         0          602         38  \n",
      "97      163      20         0          684         25  \n",
      "98       83      13         0          294         91  \n",
      "99       61       9         1          274         37  \n",
      "100     162      11         1          430         52  \n",
      "101     101      12         0          246         65  \n",
      "102     119      12         0          460         49  \n",
      "103     191      30         0          435         31  \n",
      "104     121       2         1          685         68  \n",
      "105     136      18         1          426         61  \n",
      "106      86       7         0          460         37  \n",
      "107     106      14         0          431         31  \n",
      "108      86      10         1          321         55  \n",
      "109     184      51         0          293         30  \n",
      "110      51       1         1          342         34  \n",
      "111     131      47         0          689         43  \n",
      "112     133      12         0          408         21  \n",
      "113      69       4         0          416         26  \n",
      "114      79      57         1          171         37  \n",
      "115      93       0         0          615         22  \n",
      "116      89      13         1          460         51  \n",
      "117     100      70         0          234         59  \n",
      "\n",
      "[118 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "#df.to_csv(r'C:\\Users\\Acer\\Dropbox\\UFABC\\PGC\\dataframe.csv', index = False)\n",
    "df.to_excel(r'C:\\Users\\Acer\\Dropbox\\UFABC\\PGC\\dataset-pln.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin\n",
      "admin\n",
      "Marcelo Pena\n",
      "Camilo Angelucci\n",
      "Daniele Araújo\n",
      "Camilo Angelucci\n",
      "Ivanise Gaubeur, Naomi Akiba\n",
      "Emily Takeuchi\n",
      "Cassiano Aono\n",
      "Renato Cunha\n",
      "Manuela Rodrigues\n",
      "Fábio Furlan\n",
      "Carlos Alberto-Silva\n",
      "Victoria Baptista Dias Miotto, Ronei Miotto\n",
      "Janaína Garcia\n",
      "Vanessa Verdade\n",
      "Carlos Alberto-Silva\n",
      "Marcelo Pena\n",
      "Marcelo Leigui\n",
      "Camilo Angelucci\n",
      "Hugo Suffredini\n",
      "Camila Vieira\n",
      "Amedea Seabra\n",
      "Janaína Garcia\n",
      "Fabiana Rodrigues Costa Nunes\n",
      "Janaína Garcia\n",
      "Amedea Seabra\n",
      "Marcelo Pena\n",
      "Hugo Suffredini\n",
      "Vanessa Verdade\n",
      "Daniele Araújo\n",
      "Naomi Akiba\n",
      "Vanessa Verdade\n",
      "Gloria Santucci\n",
      "Attalya Felix\n",
      "Hugo Suffredini\n",
      "Daniele Araújo\n",
      "Marcelo S. Caetano, Raquel Fornari\n",
      "Carlos Alberto-Silva, Vanessa Verdade\n",
      "Livia Seno Ferreira Camargo\n",
      "Renato Cunha\n",
      "Cassiano Aono\n",
      "Fábio Furlan\n",
      "Janaína Garcia\n",
      "Marcelo Leigui\n",
      "Fábio Furlan\n",
      "Gabriela Dias, Michele Salvador\n",
      "Hugo Suffredini, Paula Homem de Mello\n",
      "Cassiano Aono\n",
      "Vanessa Verdade\n",
      "Renato Cunha\n",
      "Daniele Araújo\n",
      "Daniele Araújo\n",
      "Felipe Cesar\n",
      "Renato Cunha\n",
      "Wesley Góis\n",
      "Jhonathan Souza\n",
      "Marcelo Pena\n",
      "Jhonathan Souza\n",
      "Marcelo Pena\n",
      "Marcelo Pena\n",
      "Felipe Cesar, Gabriela Dias\n",
      "Paula Homem de Mello, Hugo Suffredini, Felipe Cesar\n",
      "Michele Salvador, Gabriela Dias\n",
      "Michele Salvador\n",
      "Paula Homem de Mello\n",
      "Vanessa Verdade\n",
      "Gabriela Dias\n",
      "Rodrigo Papai\n",
      "Cassiano Aono, Felipe Cesar\n",
      "Pedro Henrique Thiayamiti Santos, João Henrique Quintino Palhares\n",
      "Marcelo Leigui\n",
      "Vanessa Verdade\n",
      "Vanessa Verdade\n",
      "Jhonathan Souza\n",
      "Vanessa Verdade\n",
      "Vanessa Verdade\n",
      "Davi Duarte, Everson Silva\n",
      "Felipe Cesar\n",
      "Felipe Cesar\n",
      "Livia Seno Ferreira Camargo\n",
      "Marcelo Pena\n",
      "Vanessa Ludovico, Felipe Cesar\n",
      "Marcelo Pena\n",
      "Alysson Fabio Ferrari\n",
      "Patrícia Dantoni, Paula Homem de Mello\n",
      "Felipe Cesar, Paula Homem de Mello\n",
      "Paula Homem de Mello\n",
      "Felipe Cesar, Cassiano Aono\n",
      "Vanessa Verdade\n",
      "Luis Henrique de Lima\n",
      "Renato Cunha\n",
      "Marcelo Pena\n",
      "Mónica López\n",
      "Cassiano Aono, Laiz G. Chagas, Thariny Oliveira\n",
      "Vanessa Verdade\n",
      "Gabriela Dias, Cleiton Maciel\n",
      "Gabriela Dias\n",
      "Michele Salvador, Gabriela Dias\n",
      "Gabriel Mol\n",
      "Janaína Garcia\n",
      "Renato Cunha\n",
      "Cassiano Aono\n",
      "Jhonathan Souza\n",
      "Lanna Emilli Barbosa Lucchetti, Diego de Oliveira Rogério, André Luís Pesquero de Melo, Robert Maiory Alarcon Flores\n",
      "Jéssica Oliveira Aguiar Perez, Marcos Ferrer Lima, Renato Cunha\n",
      "Leonardo Henrique de Macedo, Vitória Aparecida Procópio, Miguel Tabanez, Leonardo Martins Carneiro\n",
      "Alícia Fortunato Batista, Susan Meirelles Dantas, Gabrielle Mathias Reis, Wagner José Odilon dos Santos\n",
      "Matheus Lopes Silva, Helen Reis Modesto, Wellington Diego da Ascenção\n",
      "Marcelo Pena\n",
      "Marcelo Pena\n",
      "Marcelo Pena\n",
      "Paula Homem de Mello, Hugo Suffredini\n",
      "Paula Homem de Mello, Hugo Suffredini\n",
      "Marcelo Pena\n",
      "Livia Seno Ferreira Camargo\n",
      "Mónica López\n",
      "Marcelo Pena\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(textos2)):\n",
    "    print(textos2[i][-1][:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
