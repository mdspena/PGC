{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGC - Coleta de Dados e Criação da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import spacy\n",
    "\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo o corpus e armazenando o conteúdo completo em *content* e as linhas em *paragraphs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras: 115525\n"
     ]
    }
   ],
   "source": [
    "fileName = \"corpus-textos-DC-01-10.txt\"\n",
    "\n",
    "document = open(fileName,'r', encoding='utf-8')\n",
    "content  = document.read()\n",
    "\n",
    "document = open(fileName,'r', encoding='utf-8')\n",
    "paragraphs = document.readlines()\n",
    "\n",
    "words = re.findall(regex, content)\n",
    "\n",
    "print (f\"Quantidade de palavras: {len(words)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo parágrafos em branco. Esses parágrafos foram adicionados ao *corpus* apenas para que ficasse mais fácil de ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in paragraphs:\n",
    "    if paragraph == \"\\n\":\n",
    "        paragraphs.remove(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de parágrafos de conteúdo: 2224\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quantidade de parágrafos de conteúdo: {len(paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantas palavras diferentes estão presentes no *corpus*? Quantas vezes cada uma dessas palavras aparece no *corpus*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 14932\n"
     ]
    }
   ],
   "source": [
    "frequencies = dict([])\n",
    "for w in words:\n",
    "    w = w.lower()\n",
    "    if w not in frequencies:\n",
    "        frequencies[w] = 0\n",
    "    frequencies[w] += 1\n",
    "print (f\"Tamanho do vocabulário: {len(frequencies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq\t -\t Palavra\n",
      "5600\t -\t de\n",
      "3571\t -\t a\n",
      "3533\t -\t e\n",
      "3095\t -\t que\n",
      "2864\t -\t o\n",
      "1803\t -\t em\n",
      "1586\t -\t da\n",
      "1568\t -\t do\n",
      "1448\t -\t é\n",
      "1417\t -\t um\n",
      "1284\t -\t para\n",
      "1161\t -\t com\n",
      "1151\t -\t uma\n",
      "983\t -\t os\n",
      "882\t -\t por\n",
      "880\t -\t no\n",
      "869\t -\t como\n",
      "842\t -\t não\n",
      "824\t -\t na\n",
      "738\t -\t se\n"
     ]
    }
   ],
   "source": [
    "fs = sorted(frequencies, key=frequencies.get, reverse=True)\n",
    "print(\"Freq\\t -\\t Palavra\")\n",
    "for i in range(0,20):\n",
    "    print (f\"{frequencies[fs[i]]}\\t -\\t {fs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade e frequência das palavras após a remoção de *stopwords*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário (sem stopwords): 14607\n"
     ]
    }
   ],
   "source": [
    "stopwordsPTfile = open(\"stopwords-pt.txt\",'r', encoding='utf-8')\n",
    "stopwords = set([]) \n",
    "for s in stopwordsPTfile.readlines():\n",
    "    stopwords.add(s.strip().lower())\n",
    "    \n",
    "frequencies = dict([])\n",
    "for w in words:\n",
    "    w = w.lower()\n",
    "    if w not in stopwords:\n",
    "        if w not in frequencies:\n",
    "            frequencies[w] = 0\n",
    "        frequencies[w] += 1\n",
    "        \n",
    "print (f\"Tamanho do vocabulário (sem stopwords): {len(frequencies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq\t -\t Palavra\n",
      "239\t -\t ciência\n",
      "231\t -\t água\n",
      "155\t -\t ---\n",
      "142\t -\t tempo\n",
      "125\t -\t exemplo\n",
      "125\t -\t luz\n",
      "115\t -\t vida\n",
      "114\t -\t mundo\n",
      "112\t -\t história\n",
      "105\t -\t pesquisa\n",
      "104\t -\t química\n",
      "103\t -\t cientistas\n",
      "95\t -\t animais\n",
      "93\t -\t brasil\n",
      "90\t -\t terra\n",
      "87\t -\t física\n",
      "86\t -\t estudos\n",
      "86\t -\t moléculas\n",
      "84\t -\t vírus\n",
      "80\t -\t científica\n"
     ]
    }
   ],
   "source": [
    "fs = sorted(frequencies, key=frequencies.get, reverse=True)\n",
    "print(\"Freq\\t -\\t Palavra\")\n",
    "for i in range(0,20):\n",
    "    print (f\"{frequencies[fs[i]]}\\t -\\t {fs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_por_palavra = []\n",
    "palavras = []\n",
    "\n",
    "for word in words:\n",
    "    if(word != \"---\"):\n",
    "        palavras.append(word)\n",
    "    else:\n",
    "        textos_por_palavra.append(palavras)\n",
    "        palavras = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_por_paragrafo = []\n",
    "paragrafos = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    if(paragraph != \"---\\n\"):\n",
    "        paragrafos.append(paragraph[:-1])\n",
    "    else:\n",
    "        textos_por_paragrafo.append(paragrafos)\n",
    "        paragrafos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto *i* como um vetor de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Qual', 'a', 'diferença', 'entre', 'rinite', 'e', 'sinusite', 'acessibilidade', 'Ilustração', 'de', 'um', 'homem', 'espirrando', 'em', 'um', 'lenço', 'Existem', 'duas', 'ites', 'que', 'acometem', 'nossas', 'vias', 'aéreas', 'no', 'inverno', 'e', 'no', 'período', 'de', 'ar', 'seco', 'são', 'elas', 'sinusite', 'e', 'rinite', 'Estas', 'duas', 'inflamações', 'podem', 'se', 'manifestar', 'sempre', 'que', 'a', 'pessoa', 'tiver', 'contato', 'com', 'algum', 'patógeno', 'ou', 'com', 'substâncias', 'alergênicas', 'Elas', 'podem', 'ocorrer', 'juntas', 'ou', 'isoladamente', 'e', 'em', 'muitos', 'casos', 'a', 'rinite', 'pode', 'acarretar', 'a', 'sinusite', 'Mas', 'afinal', 'você', 'sabe', 'diferenciar', 'as', 'duas', 'A', 'rinite', 'é', 'uma', 'inflamação', 'que', 'acomete', 'as', 'mucosas', 'do', 'nariz', 'e', 'essa', 'inflamação', 'ocorre', 'por', 'conta', 'de', 'infecções', 'virais', 'ou', 'de', 'alergias', 'A', 'rinite', 'alérgica', 'é', 'mais', 'comum', 'e', 'é', 'provocada', 'por', 'partículas', 'estranhas', 'ao', 'nosso', 'corpo', 'como', 'pelos', 'de', 'animais', 'e', 'poeira', 'Os', 'sintomas', 'geralmente', 'são', 'coceira', 'no', 'nariz', 'coriza', 'obstrução', 'nasal', 'espirro', 'dor', 'de', 'cabeça', 'e', 'nos', 'olhos', 'Os', 'tratamentos', 'envolvem', 'antialérgicos', 'vacinas', 'contra', 'alergias', 'e', 'corticoides', 'Já', 'a', 'sinusite', 'é', 'uma', 'inflamação', 'nas', 'mucosas', 'dos', 'seios', 'da', 'face', 'que', 'são', 'cavidades', 'localizadas', 'no', 'interior', 'dos', 'ossos', 'faciais', 'Ela', 'geralmente', 'está', 'associada', 'a', 'infecções', 'de', 'bactérias', 'mas', 'também', 'pode', 'ser', 'ocasionada', 'por', 'vírus', 'fungos', 'e', 'alergias', 'Os', 'sintomas', 'são', 'a', 'sensação', 'de', 'cabeça', 'pesada', 'coriza', 'obstrução', 'nasal', 'tosse', 'dor', 'na', 'face', 'e', 'de', 'cabeça', 'e', 'ocasionalmente', 'febre', 'A', 'sinusite', 'pode', 'ser', 'classificada', 'como', 'aguda', 'quando', 'corre', 'por', 'até', '3', 'meses', 'e', 'crônica', 'quando', 'os', 'sintomas', 'são', 'mais', 'moderados', 'e', 'podem', 'persistir', 'por', 'mais', 'de', '3', 'meses', 'Os', 'tratamentos', 'estão', 'associados', 'ao', 'uso', 'de', 'antibióticos', 'e', 'corticoides', 'e', 'em', 'alguns', 'casos', 'específicos', 'é', 'necessária', 'a', 'realização', 'de', 'cirurgia', 'Agora', 'que', 'você', 'já', 'sabe', 'a', 'diferença', 'dos', 'dois', 'vamos', 'para', 'a', 'prevenção', 'Busque', 'manter', 'sua', 'casa', 'e', 'seu', 'ambiente', 'de', 'trabalho', 'limpos', 'evite', 'ter', 'contato', 'com', 'mofo', 'e', 'poeira', 'higienize', 'os', 'seus', 'pets', 'peludinhos', 'não', 'fume', 'pratique', 'atividade', 'física', 'hidrate-se', 'e', 'realize', 'lavagem', 'nasal', 'conforme', 'recomendação', 'médica', 'E', 'atenção', 'antes', 'de', 'utilizar', 'qualquer', 'medicamento', 'consulte', 'o', 'seu', 'farmacêutico', 'Milena', 'do', 'Nascimento']\n"
     ]
    }
   ],
   "source": [
    "print(textos_por_palavra[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto *i* como um vetor de *strings* em que cada *string* é um parágrafo do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Qual a diferença entre rinite e sinusite?', '#acessibilidade Ilustração de um homem espirrando em um lenço.', 'Existem duas “ites” que acometem nossas vias aéreas no inverno e no período de ar seco, são elas: sinusite e rinite. Estas duas inflamações podem se manifestar sempre que a pessoa tiver contato com algum patógeno ou com substâncias alergênicas. Elas podem ocorrer juntas ou isoladamente, e em muitos casos a rinite pode acarretar a sinusite. Mas, afinal, você sabe diferenciar as duas?', 'A rinite é uma inflamação que acomete as mucosas do nariz, e essa inflamação ocorre por conta de infecções virais ou de alergias. A rinite alérgica é mais comum e é provocada por partículas estranhas ao nosso corpo como pelos de animais e poeira. Os sintomas geralmente são coceira no nariz, coriza, obstrução nasal, espirro, dor de cabeça e nos olhos. Os tratamentos envolvem antialérgicos, vacinas contra alergias e corticoides.', 'Já a sinusite é uma inflamação nas mucosas dos seios da face, que são cavidades localizadas no interior dos ossos faciais. Ela geralmente está associada a infecções de bactérias, mas também pode ser ocasionada por vírus, fungos e alergias. Os sintomas são a sensação de cabeça pesada, coriza obstrução nasal, tosse, dor na face e de cabeça e ocasionalmente febre. A sinusite pode ser classificada como aguda, quando corre por até 3 meses, e crônica, quando os sintomas são mais moderados e podem persistir por mais de 3 meses. Os tratamentos estão associados ao uso de antibióticos e corticoides, e em alguns casos específicos é necessária a realização de cirurgia.', 'Agora que você já sabe a diferença dos dois vamos para a prevenção! Busque manter sua casa e seu ambiente de trabalho limpos, evite ter contato com mofo e poeira, higienize os seus pets peludinhos, não fume, pratique atividade física, hidrate-se e realize lavagem nasal, conforme recomendação médica.', 'E, atenção, antes de utilizar qualquer medicamento, consulte o seu farmacêutico!', 'Milena do Nascimento']\n"
     ]
    }
   ],
   "source": [
    "print(textos_por_paragrafo[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação dos atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação dos atributos tamanho do título, média de caracteres nos parágrafos, número de palavras e número de parágrafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do título:\n",
      " [40, 22, 65, 20, 56, 32, 36, 52, 31, 71, 46, 21, 37, 29, 37, 39, 54, 24, 14, 25, 24, 40, 23, 40, 70, 45, 32, 22, 36, 33, 25, 26, 52, 63, 36, 45, 51, 18, 34, 11, 74, 35, 20, 22, 15, 64, 23, 40, 37, 42, 52, 78, 48, 23, 71, 7, 28, 27, 44, 7, 27, 26, 29, 46, 57, 42, 53, 40, 29, 52, 45, 68, 45, 74, 54, 33, 36, 56, 45, 69, 25, 32, 27, 51, 36, 46, 42, 27, 66, 43, 42, 78, 60, 38, 22, 61, 38, 25, 91, 37, 52, 65, 49, 31, 68, 61, 37, 31, 55, 30, 34, 43, 21, 26, 37, 22, 51, 59, 71, 40, 57, 30, 34, 48, 51, 39, 34, 19, 20, 62, 40, 40, 83, 76, 48, 20, 29, 43, 49, 43, 66, 36, 42, 74, 70, 36, 48, 46, 35, 63, 17, 30, 38, 42, 41]\n"
     ]
    }
   ],
   "source": [
    "tamanhoTitulo = []\n",
    "for i in range (len(textos_por_paragrafo)):\n",
    "    tamanhoTitulo.append(len(textos_por_paragrafo[i][0]))\n",
    "\n",
    "print(\"Tamanho do título:\\n\",tamanhoTitulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de parágrafos:\n",
      " [308, 204, 180, 514, 340, 332, 472, 384, 478, 378, 265, 337, 440, 530, 342, 335, 464, 219, 518, 313, 563, 247, 301, 539, 584, 355, 451, 249, 506, 419, 387, 436, 212, 304, 612, 570, 482, 476, 562, 589, 294, 353, 316, 443, 571, 496, 555, 421, 474, 504, 184, 434, 240, 484, 358, 636, 290, 388, 240, 218, 242, 466, 476, 547, 406, 358, 599, 302, 545, 300, 540, 655, 608, 559, 567, 423, 472, 303, 391, 356, 532, 424, 398, 368, 672, 428, 425, 395, 432, 183, 645, 267, 460, 324, 309, 788, 602, 684, 294, 274, 430, 246, 460, 435, 685, 426, 460, 431, 321, 293, 342, 689, 408, 416, 171, 615, 460, 234, 809, 377, 976, 313, 477, 571, 316, 350, 392, 811, 646, 739, 645, 480, 348, 760, 404, 514, 553, 443, 519, 287, 627, 462, 490, 146, 690, 317, 249, 340, 722, 367, 511, 632, 349, 367, 320]\n"
     ]
    }
   ],
   "source": [
    "mediaParagrafos = []\n",
    "#tamanhoParagrafos = []\n",
    "aux = []\n",
    "#maior = 0\n",
    "#txtMaior = 0\n",
    "#parMaior = 0\n",
    "\n",
    "for i in range (len(textos_por_paragrafo)):\n",
    "    for j in range (1,len(textos_por_paragrafo[i])-1):\n",
    "        aux.append(len(textos_por_paragrafo[i][j]))\n",
    "        \n",
    "        #if len(textos_por_paragrafo[i][j]) > maior:\n",
    "        #    maior = len(textos_por_paragrafo[i][j])\n",
    "        #    \n",
    "        #    txtMaior = i\n",
    "        #    parMaior = j\n",
    "    \n",
    "    mediaParagrafos.append(round(sum(aux)/len(aux)))\n",
    "    #tamanhoParagrafos.append(aux)\n",
    "    aux = []\n",
    "\n",
    "#print(\"Maior parágrafo tem\",len(textos_por_paragrafo[txtMaior][parMaior]),\n",
    "#      \"caracteres\\nTexto:\",textos_por_paragrafo[txtMaior][0],\n",
    "#      \"\\nParágrafo:\\n\\t\",textos_por_paragrafo[txtMaior][parMaior])\n",
    "\n",
    "print(\"Média de parágrafos:\\n\", mediaParagrafos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras\n",
      " [345, 532, 913, 322, 557, 400, 400, 345, 577, 1129, 439, 311, 300, 516, 345, 449, 341, 799, 609, 714, 612, 375, 236, 438, 766, 381, 371, 1757, 330, 339, 292, 355, 203, 1052, 619, 363, 435, 487, 426, 678, 584, 529, 271, 691, 1079, 335, 1044, 583, 511, 668, 1031, 631, 348, 678, 342, 855, 768, 913, 515, 327, 389, 1702, 1153, 1124, 758, 947, 392, 443, 706, 1324, 810, 851, 816, 472, 697, 367, 406, 613, 973, 737, 576, 1228, 1441, 1452, 1252, 1249, 1309, 533, 1171, 651, 1341, 731, 1200, 687, 782, 749, 580, 1152, 749, 552, 1083, 685, 756, 1236, 779, 934, 554, 606, 564, 1219, 437, 1011, 987, 563, 788, 652, 608, 759, 954, 608, 1219, 886, 812, 835, 778, 443, 618, 654, 1048, 1011, 713, 917, 547, 1111, 788, 708, 948, 892, 1097, 673, 2046, 754, 1978, 724, 883, 965, 756, 803, 1026, 903, 926, 750, 667, 761, 321]\n",
      "\n",
      "Número de parágrafos\n",
      " [9, 18, 33, 6, 13, 9, 7, 7, 9, 20, 11, 7, 7, 8, 8, 10, 7, 23, 9, 16, 9, 11, 7, 7, 10, 8, 7, 46, 6, 7, 7, 7, 8, 23, 8, 6, 8, 8, 7, 10, 14, 11, 7, 11, 13, 6, 14, 11, 8, 10, 35, 11, 11, 11, 8, 11, 19, 16, 15, 11, 12, 24, 17, 15, 13, 18, 6, 11, 10, 28, 11, 10, 10, 7, 10, 7, 7, 14, 17, 15, 9, 20, 24, 25, 14, 20, 20, 10, 19, 22, 15, 18, 18, 15, 17, 8, 8, 12, 18, 14, 17, 19, 12, 19, 9, 15, 9, 11, 12, 27, 10, 11, 17, 11, 28, 9, 10, 21, 9, 12, 10, 19, 12, 11, 17, 10, 12, 7, 12, 11, 9, 14, 11, 11, 13, 10, 13, 14, 15, 16, 22, 12, 26, 31, 10, 21, 21, 17, 11, 16, 13, 9, 14, 15, 8]\n"
     ]
    }
   ],
   "source": [
    "nPalavras = []\n",
    "nParagrafos = []\n",
    "\n",
    "for i in range (len(textos_por_palavra)):\n",
    "    nPalavras.append(len(textos_por_palavra[i]))\n",
    "    nParagrafos.append(len(textos_por_paragrafo[i]))\n",
    "    \n",
    "print(\"Número de palavras\\n\", nPalavras)\n",
    "print(\"\\nNúmero de parágrafos\\n\", nParagrafos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postagging para criação dos atributos 'numSub', 'numAdj', 'numVrb', 'numNEs', 'numDet', 'numConj', 'numAdv', 'numAdp' e 'numNum'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postagging = spacy.load('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo para o título do texto 117."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = postagging(textos_por_paragrafo[117][0])\n",
    "print(parsedData,\"\\n\")\n",
    "\n",
    "for j,word in enumerate(parsedData):\n",
    "    print(\"Palavra:\",word.text,\"\\nPostag:\",word.pos_,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in parsedData:\n",
    "    if word.ent_type_:\n",
    "        print(word.text, word.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=time.perf_counter()\n",
    "\n",
    "nNounsTotal = []\n",
    "nAdjTotal = []\n",
    "nVerbTotal = []\n",
    "nNesTotal = []\n",
    "nDetTotal = []\n",
    "nConjTotal = []\n",
    "nAdvTotal = []\n",
    "nAdpTotal = []\n",
    "nNumTotal = []\n",
    "palavras_desconhecidas = []\n",
    "\n",
    "for k in range (len(textos_por_paragrafo)):\n",
    "    nNouns = 0\n",
    "    nAdj = 0\n",
    "    nVerb = 0\n",
    "    nNes = 0\n",
    "    nDet = 0\n",
    "    nConj = 0\n",
    "    nAdv = 0\n",
    "    nAdp = 0\n",
    "    nNum = 0\n",
    "    \n",
    "    for l in range (len(textos_por_paragrafo[k])):        \n",
    "        parsedData = postagging(textos_por_paragrafo[k][l])\n",
    "        \n",
    "        for j,palavra in enumerate(parsedData):\n",
    "            tag = palavra.pos_\n",
    "            if tag in [\"NOUN\",\"PROPN\"]:\n",
    "                nNouns += 1\n",
    "            elif tag in [\"ADJ\"]:\n",
    "                nAdj += 1\n",
    "            elif tag in [\"VERB\"]:\n",
    "                nVerb += 1\n",
    "            elif tag in [\"DET\"]:\n",
    "                nDet += 1\n",
    "            elif tag in [\"CONJ\",\"CCONJ\"]:\n",
    "                nConj += 1\n",
    "            elif tag in [\"ADV\"]:\n",
    "                nAdv += 1\n",
    "            elif tag in [\"NUM\"]:\n",
    "                nNum += 1\n",
    "            elif tag in [\"ADP\"]:\n",
    "                nAdp += 1\n",
    "            elif tag in [\"X\"]:\n",
    "                palavras_desconhecidas.append(palavra)\n",
    "            if palavra.ent_type_:\n",
    "                nNes += 1\n",
    "\n",
    "    nNounsTotal.append(round(nNouns/nPalavras[k],4))\n",
    "    nAdjTotal.append(round(nAdj/nPalavras[k],4))\n",
    "    nVerbTotal.append(round(nVerb/nPalavras[k],4))\n",
    "    nNesTotal.append(round(nNes/nPalavras[k],4))\n",
    "    nDetTotal.append(round(nDet/nPalavras[k],4))\n",
    "    nConjTotal.append(round(nConj/nPalavras[k],4))\n",
    "    nAdvTotal.append(round(nAdv/nPalavras[k],4))\n",
    "    nAdpTotal.append(round(nAdp/nPalavras[k],4))\n",
    "    nNumTotal.append(round(nNum/nPalavras[k],4))\n",
    "\n",
    "print(round(time.perf_counter()-t,3), \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Substantivos (%):\\n\",nNounsTotal)\n",
    "print(\"\\nAdjetivos (%):\\n\",nAdjTotal)\n",
    "print(\"\\nVerbos (%):\\n\",nVerbTotal)\n",
    "print(\"\\nEntidades nomeadas (%):\\n\",nNesTotal)\n",
    "print(\"\\nDeterminantes (%):\\n\",nDetTotal)\n",
    "print(\"\\nConjunções (%):\\n\",nConjTotal)\n",
    "print(\"\\nAdvérbios (%):\\n\",nAdvTotal)\n",
    "print(\"\\nAdposições (%):\\n\",nAdpTotal)\n",
    "print(\"\\nNumerais (%):\\n\",nNumTotal)\n",
    "print(\"\\nPalavras desconhecidas:\\n\",palavras_desconhecidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do atributo 'Pergunta'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = []\n",
    "for i in range (len(textos_por_paragrafo)):\n",
    "    titulos.append(textos_por_paragrafo[i][0])\n",
    "    \n",
    "pergunta = []\n",
    "for titulo in titulos:\n",
    "    if(titulo.find('?') != -1):\n",
    "        pergunta.append(1)\n",
    "    else:\n",
    "        pergunta.append(0)\n",
    "\n",
    "print(\"Há uma pergunta no título?\\n\", pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando todos os títulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(textos_por_paragrafo)):\n",
    "    print(textos_por_paragrafo[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do atributo 'refs', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"Post\",\"Área\",\"Rel1\",\"Rel2\",\"Rel3\"]\n",
    "relacionados = pd.read_excel(\"dataset-pgc-manual.xlsx\", usecols=col_list)\n",
    "relacionados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "    \n",
    "for i in range (len(relacionados)):\n",
    "    rel = []\n",
    "    rel.append(list(relacionados[relacionados['Post'][i] == relacionados['Rel1']].index))\n",
    "    rel.append(list(relacionados[relacionados['Post'][i] == relacionados['Rel2']].index))\n",
    "    rel.append(list(relacionados[relacionados['Post'][i] == relacionados['Rel3']].index))\n",
    "\n",
    "    for j in range (len(rel)):\n",
    "        for k in range (len(rel[j])):\n",
    "            edges.append([rel[j][k],i])\n",
    "    \n",
    "print(\"Arestas:\\n\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = ig.Graph(directed=True)\n",
    "g.add_vertices(len(df))\n",
    "\n",
    "for i in range(len(g.vs)):\n",
    "    g.vs[i][\"id\"]= i\n",
    "    g.vs[i][\"area\"]= df['Área'][i]\n",
    "    g.vs[i][\"label\"]= str(i)\n",
    "\n",
    "g.add_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de vértices no grafo:\", g.vcount())\n",
    "print(\"Número de arestas no grafo:\", g.ecount())\n",
    "print(\"Grau máximo no grafo:\", g.maxdegree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "#layers = []\n",
    "for i in range (len(df)):\n",
    "    refs.append(len(g.neighbors(i, mode='IN')))\n",
    "    #layers.append(abs(refs[i]-17))\n",
    "print(\"Referências:\\n\", refs)\n",
    "#print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_style = {}\n",
    "out_name = \"graph.pdf\"\n",
    "\n",
    "color_dict = {\"Biologia\": \"green\",\n",
    "              \"Ciência\": \"red\",\n",
    "              \"Química\": \"yellow\",\n",
    "              \"Física\": \"blue\",\n",
    "              \"História\": \"pink\",\n",
    "              \"Medicina\": \"cyan\",\n",
    "              \"Astronomia\": \"orange\",\n",
    "              \"Atualidades\": \"brown\",\n",
    "              \"Matemática\": \"olive\",\n",
    "              \"Psicologia\": \"purple\",\n",
    "              \"Tecnologia\": \"gray\"}\n",
    "\n",
    "visual_style[\"layout\"] = g.layout_sugiyama(layers=layers, hgap=100.0, vgap=2000.0)\n",
    "#layout = g.layout_sugiyama(layers=layers, hgap=110, vgap=1000)\n",
    "#layout_bounding_box = layout.bounding_box()\n",
    "#layout.translate((-1*layout_bounding_box.left, -1*layout_bounding_box.top))\n",
    "#layout_bounding_box = layout.bounding_box()\n",
    "visual_style[\"bbox\"] = (12000,4000)\n",
    "visual_style[\"margin\"] = 100\n",
    "visual_style[\"vertex_size\"] = 70\n",
    "visual_style[\"vertex_label_size\"] = 30\n",
    "visual_style[\"edge_curved\"] = False\n",
    "visual_style[\"edge_widht\"] = 2\n",
    "edges_colors = []\n",
    "for i in range (len(g.es)): edges_colors.append(g.vs[g.es[i].source][\"area\"])\n",
    "visual_style[\"edge_color\"] = [color_dict[area] for area in edges_colors]\n",
    "visual_style[\"vertex_color\"] = [color_dict[area] for area in g.vs[\"area\"]]\n",
    "#visual_style[\"layout\"] = g.layout_lgl()\n",
    "\n",
    "#ig.plot(g, out_name, keep_aspect_ratio=True, layout=layout, bbox=layout_bounding_box, **visual_style);\n",
    "ig.plot(g, out_name, **visual_style);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 149\n",
    "print(f\"Texto {i} - {textos_por_paragrafo[i][0][:-1]}\")\n",
    "print(f\"Autor: {textos_por_paragrafo[i][-1][:-1]}\")\n",
    "print(f\"Número de palavras: {nPalavras[i]}\")\n",
    "print(f\"Número de parágrafos: {nParagrafos[i]}\") ####### Título e Autor contam como parágrafos\n",
    "print(f\"Número de substantivos: {nNounsTotal[i]}\")\n",
    "print(f\"Número de adjetivos: {nAdjTotal[i]}\")\n",
    "print(f\"Número de verbos: {nVerbTotal[i]}\")\n",
    "print(f\"Número de Entidades Nomeadas: {nNesTotal[i]}\")\n",
    "print(f\"Número de Determinantes:\",nDetTotal[i])\n",
    "print(f\"Número de Conjunções:\",nConjTotal[i])\n",
    "print(f\"Número de Advérbios:\",nAdvTotal[i])\n",
    "print(f\"Número de Adposições:\",nAdpTotal[i])\n",
    "print(f\"Número de Numerais:\",nNumTotal[i])\n",
    "print(f\"Tamanho médio dos parágrafos:\",mediaParagrafos[i])\n",
    "print(f\"Número de caracteres do título:\",tamanhoTitulo[i])\n",
    "print(f\"Número de Desconhecidos:\",xTotal[i])\n",
    "print(f\"É uma pergunta?: {pergunta[i]}\")\n",
    "print(f\"Vezes relacionado: {refs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes = ['numPal', 'numPar','numSub', 'numAdj', 'numVrb', 'numNEs','numDet',\n",
    "         'numConj','numAdv','numAdp','numNum','Pergunta','tamMedioParagraf','tamTitulo', 'refs']\n",
    "df = pd.DataFrame(list(zip(nPalavras, nParagrafos, nNounsTotal, nAdjTotal, nVerbTotal, nNesTotal,\n",
    "                           nDetTotal, nConjTotal, nAdvTotal, nAdpTotal, nNumTotal, \n",
    "                           pergunta, mediaParagrafos, tamanhoTitulo, refs)),columns=nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "df.to_excel('dataset-pln.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(textos_por_paragrafo)):\n",
    "    print(textos_por_paragrafo[i][-1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(\"logo3.png\")\n",
    "\n",
    "colormap = ListedColormap(['green','#9DA219','black'])\n",
    "cloud = WordCloud(background_color='white',\n",
    "                 colormap=colormap,\n",
    "                 max_words=100,\n",
    "                 mask=mask)\n",
    "\n",
    "cloud.fit_words(frequencies)\n",
    "plt.imshow(cloud);\n",
    "cloud.to_file('cloud2.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
